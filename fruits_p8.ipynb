{"cells": [{"metadata": {}, "id": "ce8140a4", "cell_type": "markdown", "source": "# D\u00e9ployez un mod\u00e8le dans le cloud\n\n\n# Sommaire :\n\n**1. Pr\u00e9ambule**<br />\n&emsp;1.1 Probl\u00e9matique<br />\n&emsp;1.2 Objectifs dans ce projet<br />\n&emsp;1.3 D\u00e9roulement des \u00e9tapes du projet<br />\n**2. Choix techniques g\u00e9n\u00e9raux retenus**<br />\n&emsp;2.1 Calcul distribu\u00e9 avec pyspark<br />\n&emsp;2.2 Transfert Learning<br />\n**3. D\u00e9ploiement de la solution sur le cloud avec JupyterHub**<br />\n&emsp;3.1 Import des librairies<br />\n&emsp;3.2 D\u00e9finition des PATH pour charger les images et enregistrer les r\u00e9sultats<br />\n&emsp;3.3 Traitement des donn\u00e9es<br />\n&emsp;&emsp;3.3.1 Chargement des donn\u00e9es<br />\n&emsp;&emsp;3.3.2 Pr\u00e9paration du mod\u00e8le<br />\n&emsp;&emsp;3.3.3 D\u00e9finition du processus de chargement des images et application <br />\n&emsp;&emsp;&emsp;&emsp;&emsp;de leur featurisation \u00e0 travers l'utilisation de pandas UDF<br />\n&emsp;&emsp;3.3.4 R\u00e9duction de dimension PCA <br />\n&emsp;&emsp;3.3.5 Ex\u00e9cution des actions d'extractions de features<br />\n&emsp;3.6 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat<br />\n"}, {"metadata": {}, "id": "11654d3e", "cell_type": "markdown", "source": "# 1. Pr\u00e9ambule\n\n## 1.1 Probl\u00e9matique\n\nLa tr\u00e8s jeune start-up de l'AgriTech, nomm\u00e9e \"**Fruits**!\", <br />\ncherche \u00e0 proposer des solutions innovantes pour la r\u00e9colte des fruits.\n\nLa volont\u00e9 de l\u2019entreprise est de pr\u00e9server la biodiversit\u00e9 des fruits <br />\nen permettant des traitements sp\u00e9cifiques pour chaque esp\u00e8ce de fruits <br />\nen d\u00e9veloppant des robots cueilleurs intelligents.\n\nLa start-up souhaite dans un premier temps se faire conna\u00eetre en mettant <br />\n\u00e0 disposition du grand public une application mobile qui permettrait aux <br />\nutilisateurs de prendre en photo un fruit et d'obtenir des informations sur ce fruit.\n\nPour la start-up, cette application permettrait de sensibiliser le grand public <br /> \n\u00e0 la biodiversit\u00e9 des fruits et de mettre en place une premi\u00e8re version du moteur <br />\nde classification des images de fruits.\n\nDe plus, le d\u00e9veloppement de l\u2019application mobile permettra de construire <br />\nune premi\u00e8re version de l'architecture **Big Data** n\u00e9cessaire.\n\n## 1.2 Objectifs dans ce projet\n\n1. D\u00e9velopper une premi\u00e8re cha\u00eene de traitement des donn\u00e9es qui <br />\n   comprendra le **preprocessing** et une \u00e9tape de **r\u00e9duction de dimension**.\n2. Tenir compte du fait que <u>le volume de donn\u00e9es va augmenter <br />\n   tr\u00e8s rapidement</u> apr\u00e8s la livraison de ce projet, ce qui implique de:\n - D\u00e9ployer le traitement des donn\u00e9es dans un environnement **Big Data**\n - D\u00e9velopper les scripts en **pyspark** pour effectuer du **calcul distribu\u00e9**"}, {"metadata": {}, "id": "2c9ceaf5", "cell_type": "markdown", "source": "# 2 Choix des techniques g\u00e9n\u00e9raux retenus "}, {"metadata": {}, "id": "b43f6790", "cell_type": "markdown", "source": "## 2.1 Calcul distribu\u00e9\n\nL\u2019\u00e9nonc\u00e9 du projet nous impose de d\u00e9velopper des scripts en **pyspark** <br />\nafin de <u>prendre en compte l\u2019augmentation tr\u00e8s rapide du volume <br />\nde donn\u00e9 apr\u00e8s la livraison du projet</u>.\n\nPour comprendre rapidement et simplement ce qu\u2019est **pyspark** <br />\net son principe de fonctionnement, nous vous conseillons de lire <br />\ncet article : [PySpark : Tout savoir sur la librairie Python](https://datascientest.com/pyspark)\n\n<u>Le d\u00e9but de l\u2019article nous dit ceci </u>:<br />\n\u00ab *Lorsque l\u2019on parle de traitement de bases de donn\u00e9es sur python, <br />\non pense imm\u00e9diatement \u00e0 la librairie pandas. Cependant, lorsqu\u2019on a <br />\naffaire \u00e0 des bases de donn\u00e9es trop massives, les calculs deviennent trop lents.<br />\nHeureusement, il existe une autre librairie python, assez proche <br />\nde pandas, qui permet de traiter des tr\u00e8s grandes quantit\u00e9s de donn\u00e9es : PySpark.<br />\nApache Spark est un framework open-source d\u00e9velopp\u00e9 par l\u2019AMPLab <br />\nde UC Berkeley permettant de traiter des bases de donn\u00e9es massives <br />\nen utilisant le calcul distribu\u00e9, technique qui consiste \u00e0 exploiter <br />\nplusieurs unit\u00e9s de calcul r\u00e9parties en clusters au profit d\u2019un seul <br />\nprojet afin de diviser le temps d\u2019ex\u00e9cution d\u2019une requ\u00eate.<br />\nSpark a \u00e9t\u00e9 d\u00e9velopp\u00e9 en Scala et est au meilleur de ses capacit\u00e9s <br />\ndans son langage natif. Cependant, la librairie PySpark propose de <br />\nl\u2019utiliser avec le langage Python, en gardant des performances <br />\nsimilaires \u00e0 des impl\u00e9mentations en Scala.<br />\nPyspark est donc une bonne alternative \u00e0 la librairie pandas lorsqu\u2019on <br />\ncherche \u00e0 traiter des jeux de donn\u00e9es trop volumineux qui entra\u00eenent <br />\ndes calculs trop chronophages.* \u00bb\n\nComme nous le constatons, **pySpark** est un moyen de communiquer <br />\navec **Spark** via le langage **Python**.<br />\n**Spark**, quant \u00e0 lui, est un outil qui permet de g\u00e9rer et de coordonner <br />\nl'ex\u00e9cution de t\u00e2ches sur des donn\u00e9es \u00e0 travers un groupe d'ordinateurs. <br />\n<u>Spark (ou Apache Spark) est un framework open source de calcul distribu\u00e9 <br />\nin-memory pour le traitement et l'analyse de donn\u00e9es massives</u>.\n\nUn autre [article tr\u00e8s int\u00e9ressant et beaucoup plus complet pour <br />\ncomprendre le **fonctionnement de Spark**](https://www.veonum.com/apache-spark-pour-les-nuls/), ainsi que le r\u00f4le <br />\ndes **Spark Session** que nous utiliserons dans ce projet.\n\n<u>Voici \u00e9galement un extrait</u>:\n\n*Les applications Spark se composent d\u2019un pilote (\u00ab\u202fdriver process\u202f\u00bb) <br />\net de plusieurs ex\u00e9cuteurs (\u00ab\u202fexecutor processes\u202f\u00bb). Il peut \u00eatre configur\u00e9 <br />\npour \u00eatre lui-m\u00eame l\u2019ex\u00e9cuteur (local mode) ou en utiliser autant que <br />\nn\u00e9cessaire pour traiter l\u2019application, Spark prenant en charge la mise <br />\n\u00e0 l\u2019\u00e9chelle automatique par une configuration d\u2019un nombre minimum <br />\net maximum d\u2019ex\u00e9cuteurs.*\n\n![Sch\u00e9ma de Spark](img/spark-schema.png)\n\n*Le driver (parfois appel\u00e9 \u00ab\u202fSpark Session\u202f\u00bb) distribue et planifie <br />\nles t\u00e2ches entre les diff\u00e9rents ex\u00e9cuteurs qui les ex\u00e9cutent et permettent <br />\nun traitement r\u00e9parti. Il est le responsable de l\u2019ex\u00e9cution du code <br />\nsur les diff\u00e9rentes machines.\n\nChaque ex\u00e9cuteur est un processus Java Virtual Machine (JVM) distinct <br />\ndont il est possible de configurer le nombre de CPU et la quantit\u00e9 de <br />\nm\u00e9moire qui lui est allou\u00e9. <br />\nUne seule t\u00e2che peut traiter un fractionnement de donn\u00e9es \u00e0 la fois.*\n\nDans les deux environnements (Local et Cloud) nous utiliserons donc **Spark** <br />\net nous l\u2019exploiterons \u00e0 travers des scripts python gr\u00e2ce \u00e0 **PySpark**.\n\nDans la <u>version locale</u> de notre script nous **simulerons <br />\nle calcul distribu\u00e9** afin de valider que notre solution fonctionne.<br />\nDans la <u>version cloud</u> nous **r\u00e9aliserons les op\u00e9rations sur un cluster de machine**."}, {"metadata": {}, "id": "e2f84987", "cell_type": "markdown", "source": "## 2.2 Transfert Learning\n\nL'\u00e9nonc\u00e9 du projet nous demande \u00e9galement de <br />\nr\u00e9aliser une premi\u00e8re cha\u00eene de traitement <br />\ndes donn\u00e9es qui comprendra le preprocessing et <br />\nune \u00e9tape de r\u00e9duction de dimension.\n\nIl est \u00e9galement pr\u00e9cis\u00e9 qu'il n'est pas n\u00e9cessaire <br />\nd'entra\u00eener un mod\u00e8le pour le moment.\n\nNous d\u00e9cidons de partir sur une solution de **transfert learning**.\n\nSimplement, le **transfert learning** consiste <br />\n\u00e0 utiliser la connaissance d\u00e9j\u00e0 acquise <br />\npar un mod\u00e8le entra\u00een\u00e9 (ici **MobileNetV2**) pour <br />\nl'adapter \u00e0 notre probl\u00e9matique.\n\nNous allons fournir au mod\u00e8le nos images, et nous allons <br />\n<u>r\u00e9cup\u00e9rer l'avant derni\u00e8re couche</u> du mod\u00e8le.<br />\nEn effet la derni\u00e8re couche de mod\u00e8le est une couche softmax <br />\nqui permet la classification des images ce que nous ne <br />\nsouhaitons pas dans ce projet.\n\nL'avant derni\u00e8re couche correspond \u00e0 un **vecteur <br />\nr\u00e9duit** de dimension (1,1,1280).\n\nCela permettra de r\u00e9aliser une premi\u00e8re version du moteur <br />\npour la classification des images des fruits.\n\n**MobileNetV2** a \u00e9t\u00e9 retenu pour sa <u>rapidit\u00e9 d'ex\u00e9cution</u>, <br />\nparticuli\u00e8rement adapt\u00e9e pour le traitement d'un gros volume <br />\nde donn\u00e9es ainsi que la <u>faible dimensionnalit\u00e9 du vecteur <br />\nde caract\u00e9ristique en sortie</u> (1,1,1280)"}, {"metadata": {}, "id": "0d84fad1", "cell_type": "markdown", "source": "# 3. D\u00e9ploiement de la solution sur le cloud avec JupyterHub"}, {"metadata": {}, "id": "586d27a9", "cell_type": "markdown", "source": "# 3.1 Import des librairies"}, {"metadata": {"trusted": true}, "id": "7aca7c32", "cell_type": "code", "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport io\nimport os\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras import Model\nfrom pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\nfrom pyspark.ml.feature import PCA, VectorAssembler, VectorIndexer\nfrom pyspark.ml.linalg import Vectors, VectorUDT\nfrom pyspark.sql.functions import udf", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "stream", "text": "The code failed because of a fatal error:\n\tSession 0 did not start up in 60 seconds..\n\nSome things to try:\na) Make sure Spark has enough available resources for Jupyter to create a Spark context.\nb) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\nc) Restart the kernel.\n", "name": "stderr"}]}, {"metadata": {}, "id": "8d6e080b", "cell_type": "markdown", "source": "# 3.2 D\u00e9finition des PATH pour charger les images et enregistrer les r\u00e9sultats"}, {"metadata": {"trusted": true}, "id": "6f73f095", "cell_type": "code", "source": "PATH = 's3://workspace8'\nPATH_Data = PATH+'/Test'\nPATH_Result = PATH+'/results/'\nprint('PATH:        '+\\\n      PATH+'\\nPATH_Data:   '+\\\n      PATH_Data+'\\nPATH_Result: '+PATH_Result)", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "The code failed because of a fatal error:\n\tSession 0 did not start up in 60 seconds..\n\nSome things to try:\na) Make sure Spark has enough available resources for Jupyter to create a Spark context.\nb) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\nc) Restart the kernel.\n", "name": "stderr"}]}, {"metadata": {}, "id": "85bbde52", "cell_type": "markdown", "source": "# 3.3 Traitement des donn\u00e9es"}, {"metadata": {}, "id": "92d3cfe4", "cell_type": "markdown", "source": "# 3.3.1 Chargement des donn\u00e9es"}, {"metadata": {"trusted": false}, "id": "3175ed9b", "cell_type": "code", "source": "images = spark.read.format(\"binaryFile\") \\\n  .option(\"pathGlobFilter\", \"*.jpg\") \\\n  .option(\"recursiveFileLookup\", \"true\") \\\n  .load(PATH_Data)", "execution_count": 7, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {"trusted": false}, "id": "5206efe5", "cell_type": "code", "source": "images.show(5)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "id": "4b6395c1", "cell_type": "code", "source": "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\nprint(images.printSchema())\nprint(images.select('path','label').show(5,False))", "execution_count": 8, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- path: string (nullable = true)\n |-- modificationTime: timestamp (nullable = true)\n |-- length: long (nullable = true)\n |-- content: binary (nullable = true)\n |-- label: string (nullable = true)\n\nNone\n+---------------------------------------------+----------+\n|path                                         |label     |\n+---------------------------------------------+----------+\n|s3://workspace8/Test/Watermelon/r_106_100.jpg|Watermelon|\n|s3://workspace8/Test/Watermelon/r_109_100.jpg|Watermelon|\n|s3://workspace8/Test/Watermelon/r_108_100.jpg|Watermelon|\n|s3://workspace8/Test/Watermelon/r_107_100.jpg|Watermelon|\n|s3://workspace8/Test/Watermelon/r_95_100.jpg |Watermelon|\n+---------------------------------------------+----------+\nonly showing top 5 rows\n\nNone"}]}, {"metadata": {"trusted": false}, "id": "e9e6b7d7", "cell_type": "code", "source": "images.show(5)", "execution_count": 7, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+-------------------+------+--------------------+----------+\n|                path|   modificationTime|length|             content|     label|\n+--------------------+-------------------+------+--------------------+----------+\n|s3://workspace8/T...|2023-11-03 15:11:41|  7353|[FF D8 FF E0 00 1...|Watermelon|\n|s3://workspace8/T...|2023-11-03 15:12:20|  7350|[FF D8 FF E0 00 1...|Watermelon|\n|s3://workspace8/T...|2023-11-03 15:12:46|  7349|[FF D8 FF E0 00 1...|Watermelon|\n|s3://workspace8/T...|2023-11-03 15:12:28|  7348|[FF D8 FF E0 00 1...|Watermelon|\n|s3://workspace8/T...|2023-11-03 15:12:42|  7328|[FF D8 FF E0 00 1...|Watermelon|\n+--------------------+-------------------+------+--------------------+----------+\nonly showing top 5 rows"}]}, {"metadata": {"trusted": false}, "id": "5d149b2b", "cell_type": "code", "source": "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\nprint(images.printSchema())\nprint(images.select('path','label').show(5,False))", "execution_count": 9, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- path: string (nullable = true)\n |-- modificationTime: timestamp (nullable = true)\n |-- length: long (nullable = true)\n |-- content: binary (nullable = true)\n |-- label: string (nullable = true)\n\nNone\n+---------------------------------------------+----------+\n|path                                         |label     |\n+---------------------------------------------+----------+\n|s3://workspace8/Test/Watermelon/r_106_100.jpg|Watermelon|\n|s3://workspace8/Test/Watermelon/r_109_100.jpg|Watermelon|\n|s3://workspace8/Test/Watermelon/r_108_100.jpg|Watermelon|\n|s3://workspace8/Test/Watermelon/r_107_100.jpg|Watermelon|\n|s3://workspace8/Test/Watermelon/r_95_100.jpg |Watermelon|\n+---------------------------------------------+----------+\nonly showing top 5 rows\n\nNone"}]}, {"metadata": {"trusted": false}, "id": "786f3d3d", "cell_type": "code", "source": "brodcast_weights = sc.broadcast(new_model.get_weights())", "execution_count": 13, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {}, "id": "0776a748", "cell_type": "markdown", "source": "# 3.3.2 Pr\u00e9paration du mod\u00e8le "}, {"metadata": {"trusted": false}, "id": "8def3b37", "cell_type": "code", "source": "def model_fn():\n    \"\"\"\n    Returns a MobileNetV2 model with top layer removed \n    and broadcasted pretrained weights.\n    \"\"\"\n    model = MobileNetV2(weights='imagenet',\n                        include_top=True,\n                        input_shape=(224, 224, 3))\n    for layer in model.layers:\n        layer.trainable = False\n    new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)\n    new_model.set_weights(brodcast_weights.value)\n    return new_model", "execution_count": 14, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {}, "id": "46eeaaef", "cell_type": "markdown", "source": "# 3.3.3 D\u00e9finition du processus de chargement des images et application de leur featurisation \u00e0 travers l'utilisation de pandas UDF"}, {"metadata": {"trusted": false}, "id": "c1ef33de", "cell_type": "code", "source": "def preprocess(content):\n    \"\"\"\n    Preprocesses raw image bytes for prediction.\n    \"\"\"\n    img = Image.open(io.BytesIO(content)).resize([224, 224])\n    arr = img_to_array(img)\n    return preprocess_input(arr)\n\ndef featurize_series(model, content_series):\n    \"\"\"\n    Featurize a pd.Series of raw images using the input model.\n    :return: a pd.Series of image features\n    \"\"\"\n    input = np.stack(content_series.map(preprocess))\n    preds = model.predict(input)\n    # For some layers, output features will be multi-dimensional tensors.\n    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n    output = [p.flatten() for p in preds]\n    return pd.Series(output)\n\n@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\ndef featurize_udf(content_series_iter):\n    '''\n    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n\n    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n                              is a pandas Series of image data.\n    '''\n    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n    # for multiple data batches.  This amortizes the overhead of loading big models.\n    model = model_fn()\n    for content_series in content_series_iter:\n        yield featurize_series(model, content_series)", "execution_count": 15, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "/mnt/yarn/usercache/livy/appcache/application_1699552026835_0005/container_1699552026835_0005_01_000001/pyspark.zip/pyspark/sql/pandas/functions.py:403: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details."}]}, {"metadata": {"trusted": false}, "id": "f7715e71", "cell_type": "code", "source": "# 1280 features sont extraites par images du mod\u00e8le MobileNetV2\nfeatures_df = images.repartition(20).select(col(\"path\"),\n                                            col(\"label\"),\n                                            featurize_udf(\"content\").alias(\"features\")\n                                           )", "execution_count": 7, "outputs": [{"ename": "NameError", "evalue": "name 'images' is not defined", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1280 features sont extraites par images du mod\u00e8le MobileNetV2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m features_df \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mrepartition(\u001b[38;5;241m20\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m                                             col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m                                             featurize_udf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m                                            )\n", "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"]}]}, {"metadata": {"trusted": false}, "id": "f2ef6a04", "cell_type": "code", "source": "features_df.select('path').show(5)", "execution_count": 16, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|                path|\n+--------------------+\n|s3://workspace8/T...|\n|s3://workspace8/T...|\n|s3://workspace8/T...|\n|s3://workspace8/T...|\n|s3://workspace8/T...|\n+--------------------+\nonly showing top 5 rows"}]}, {"metadata": {"trusted": false}, "id": "f006e2ed", "cell_type": "code", "source": "print(PATH_Result)", "execution_count": 17, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "s3://workspace8/results"}]}, {"metadata": {"trusted": false}, "id": "ed89f159", "cell_type": "code", "source": "ud_f = udf(lambda r: Vectors.dense(r), VectorUDT())\ndf = features_df.withColumn('features', ud_f('features'))", "execution_count": 22, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {"trusted": false}, "id": "c22ad10b", "cell_type": "code", "source": "df.show(5)", "execution_count": null, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "0109d0939d4a48d7ba300f62710d25f0", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {}, "id": "03bb402d", "cell_type": "markdown", "source": "# 3.3.4 R\u00e9duction de dimension PCA"}, {"metadata": {"trusted": false}, "id": "58534e62", "cell_type": "code", "source": "# Passage de dimensions de 1280 \u00e0 1000 \npca = PCA(k=1000, inputCol=\"features\", outputCol=\"reduction_features\")", "execution_count": 23, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {"trusted": false}, "id": "abbea73f", "cell_type": "code", "source": "pca = pca.fit(df)", "execution_count": 24, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {"trusted": false}, "id": "ecb6e8a1", "cell_type": "code", "source": "# 1 % de perte d'information avec 1000 dimensions\nsum(pca.explainedVariance[:1000])", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "id": "5854c9e7", "cell_type": "code", "source": "# Passage de dimensions de 1280 \u00e0 400 \npca = PCA(k=400, inputCol=\"features\", outputCol=\"reduction_features\")", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "id": "06dfcd22", "cell_type": "code", "source": "pca = pca.fit(df)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "id": "65172f89", "cell_type": "code", "source": "# 5 % de perte d'information avec 400 dimensions\nsum(pca.explainedVariance[:400])", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "id": "bae29d95", "cell_type": "code", "source": "ps_pca = pca.transform(df)\n", "execution_count": 25, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {"trusted": false}, "id": "3da089a9", "cell_type": "code", "source": "ps_pca.select('reduction_features').show(10)", "execution_count": 26, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|  reduction_features|\n+--------------------+\n|[-1.5997433737116...|\n|[-3.8210221647130...|\n|[-3.7545830196284...|\n|[-2.8491111407258...|\n|[-2.8817704189352...|\n|[-3.3311643184080...|\n|[1.13456750300022...|\n|[-1.8620623894754...|\n|[-3.6497412501985...|\n|[-5.3369387630205...|\n+--------------------+\nonly showing top 10 rows"}]}, {"metadata": {"trusted": false}, "id": "8ce73741", "cell_type": "code", "source": "np.array(pca.explainedVariance)", "execution_count": 31, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "array([0.11025705, 0.08229517, 0.06893004, 0.05263199, 0.03212438,\n       0.0294074 , 0.0259836 , 0.02564273, 0.02107345, 0.01985178,\n       0.01610656, 0.01571898, 0.01496373, 0.01350037, 0.01288464,\n       0.01197522, 0.0119051 , 0.01088079, 0.01021353, 0.01000312,\n       0.00933051, 0.00857012, 0.0082015 , 0.00771912, 0.00729559,\n       0.0071514 , 0.00679508, 0.00658153, 0.00620601, 0.00601148,\n       0.0057978 , 0.00563653, 0.00526852, 0.00501938, 0.00497602,\n       0.00479603, 0.00462561, 0.00438635, 0.00430463, 0.00404711,\n       0.0039914 , 0.00387078, 0.00381646, 0.00370534, 0.00367309,\n       0.00356539, 0.00349344, 0.00331452, 0.00325374, 0.00310388,\n       0.00307751, 0.00301878, 0.00293913, 0.00285057, 0.00282252,\n       0.00273707, 0.00264228, 0.00257282, 0.00252379, 0.00251953,\n       0.00245173, 0.00236026, 0.0023477 , 0.00229504, 0.00226674,\n       0.00217708, 0.00212263, 0.00206343, 0.0019949 , 0.00197748,\n       0.00195343, 0.00191285, 0.00189625, 0.00184476, 0.00180025,\n       0.00176312, 0.00175142, 0.00171942, 0.00169927, 0.00167206,\n       0.00164261, 0.00160114, 0.0015588 , 0.00155316, 0.0015305 ,\n       0.00149356, 0.00147951, 0.00145056, 0.00143988, 0.00141365,\n       0.00140445, 0.001384  , 0.00134595, 0.00132615, 0.00131315,\n       0.00130561, 0.00125937, 0.00124134, 0.00123094, 0.00122192])"}]}, {"metadata": {"trusted": false}, "id": "ae414dc7", "cell_type": "code", "source": "fig, axes = plt.subplots(figsize=(8,8))\naxes.set_xticks(np.arange(100))\naxes.plot(np.arange(1,101), np.cumsum(np.array(pca.explainedVariance)))", "execution_count": 29, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "[<matplotlib.lines.Line2D object at 0x7fc898aaef50>]"}]}, {"metadata": {"trusted": false}, "id": "5e7c4677", "cell_type": "code", "source": "df_pcatr = ps_pca.select(['path','label',ps_pca['reduction_features'].cast('string')])", "execution_count": 30, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {}, "id": "2302db8f", "cell_type": "markdown", "source": "# 3.3.5 Ex\u00e9cution des actions d'extractions de feature"}, {"metadata": {"trusted": false}, "id": "6f1ae1aa", "cell_type": "code", "source": "df_pcatr.write.mode(\"overwrite\").parquet('s3://workspace8/results/')", "execution_count": 32, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {}, "id": "64255591", "cell_type": "markdown", "source": "# 3.6 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat"}, {"metadata": {"trusted": false}, "id": "7edb20eb", "cell_type": "code", "source": "df = pd.read_parquet('s3://workspace8/results/')\ndf", "execution_count": 33, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}, {"name": "stdout", "output_type": "stream", "text": "                                                    path  ...                                 reduction_features\n0       s3://workspace8/Test/Cucumber Ripe/r_165_100.jpg  ...  [1.6773020002289143,1.7483399145361351,-1.3805...\n1       s3://workspace8/Test/Cucumber Ripe/r_161_100.jpg  ...  [1.301202286620246,1.2825054892830472,-3.26622...\n2             s3://workspace8/Test/Raspberry/108_100.jpg  ...  [2.074106398725068,5.335605474536186,3.1078432...\n3             s3://workspace8/Test/Pineapple/189_100.jpg  ...  [-4.562556825992316,5.331880594886458,-0.83085...\n4         s3://workspace8/Test/Cauliflower/r_299_100.jpg  ...  [-3.9330013962328554,4.3481373459280945,1.1008...\n...                                                  ...  ...                                                ...\n15986         s3://workspace8/Test/Corn Husk/233_100.jpg  ...  [-2.882837935137558,6.80602655848726,3.7090769...\n15987  s3://workspace8/Test/Banana Lady Finger/r_51_1...  ...  [-3.282862304118072,0.5987949116352559,2.44401...\n15988      s3://workspace8/Test/Banana Red/r_111_100.jpg  ...  [-0.3200573019802308,6.685052804960648,2.76517...\n15989           s3://workspace8/Test/Banana/r_60_100.jpg  ...  [-3.2987447542296384,2.925552238471011,3.61098...\n15990      s3://workspace8/Test/Banana Red/r_130_100.jpg  ...  [-1.1944118751709927,6.143006471636359,2.36625...\n\n[15991 rows x 3 columns]"}]}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": "python"}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "file_extension": ".py", "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 5}